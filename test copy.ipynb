{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dcbf3ad",
   "metadata": {},
   "source": [
    "Cell codes copy-pasted from main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab14cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "36a6b5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bid_open</th>\n",
       "      <th>bid_high</th>\n",
       "      <th>bid_low</th>\n",
       "      <th>bid_close</th>\n",
       "      <th>ask_open</th>\n",
       "      <th>ask_high</th>\n",
       "      <th>ask_low</th>\n",
       "      <th>ask_close</th>\n",
       "      <th>bid_avg</th>\n",
       "      <th>ask_avg</th>\n",
       "      <th>spread_avg</th>\n",
       "      <th>tick_count</th>\n",
       "      <th>mid_avg</th>\n",
       "      <th>log_mid_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-09-22 00:00:00</th>\n",
       "      <td>4.26516</td>\n",
       "      <td>4.26579</td>\n",
       "      <td>4.26515</td>\n",
       "      <td>4.26534</td>\n",
       "      <td>4.26769</td>\n",
       "      <td>4.2687</td>\n",
       "      <td>4.26725</td>\n",
       "      <td>4.2686</td>\n",
       "      <td>4.265448</td>\n",
       "      <td>4.267819</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>111</td>\n",
       "      <td>4.266634</td>\n",
       "      <td>-0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-22 00:01:00</th>\n",
       "      <td>4.26573</td>\n",
       "      <td>4.26573</td>\n",
       "      <td>4.26534</td>\n",
       "      <td>4.26534</td>\n",
       "      <td>4.26725</td>\n",
       "      <td>4.2686</td>\n",
       "      <td>4.26715</td>\n",
       "      <td>4.2680</td>\n",
       "      <td>4.265488</td>\n",
       "      <td>4.267666</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>66</td>\n",
       "      <td>4.266577</td>\n",
       "      <td>-0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-22 00:02:00</th>\n",
       "      <td>4.26556</td>\n",
       "      <td>4.26556</td>\n",
       "      <td>4.26534</td>\n",
       "      <td>4.26556</td>\n",
       "      <td>4.26720</td>\n",
       "      <td>4.2680</td>\n",
       "      <td>4.26720</td>\n",
       "      <td>4.2672</td>\n",
       "      <td>4.265453</td>\n",
       "      <td>4.267497</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>33</td>\n",
       "      <td>4.266475</td>\n",
       "      <td>-0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-22 00:03:00</th>\n",
       "      <td>4.26534</td>\n",
       "      <td>4.26611</td>\n",
       "      <td>4.26534</td>\n",
       "      <td>4.26570</td>\n",
       "      <td>4.26770</td>\n",
       "      <td>4.2684</td>\n",
       "      <td>4.26720</td>\n",
       "      <td>4.2684</td>\n",
       "      <td>4.265753</td>\n",
       "      <td>4.267780</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>62</td>\n",
       "      <td>4.266767</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-22 00:04:00</th>\n",
       "      <td>4.26606</td>\n",
       "      <td>4.26606</td>\n",
       "      <td>4.26560</td>\n",
       "      <td>4.26560</td>\n",
       "      <td>4.26792</td>\n",
       "      <td>4.2684</td>\n",
       "      <td>4.26784</td>\n",
       "      <td>4.2684</td>\n",
       "      <td>4.265877</td>\n",
       "      <td>4.268109</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>33</td>\n",
       "      <td>4.266993</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bid_open  bid_high  bid_low  bid_close  ask_open  \\\n",
       "timestamp                                                               \n",
       "2025-09-22 00:00:00   4.26516   4.26579  4.26515    4.26534   4.26769   \n",
       "2025-09-22 00:01:00   4.26573   4.26573  4.26534    4.26534   4.26725   \n",
       "2025-09-22 00:02:00   4.26556   4.26556  4.26534    4.26556   4.26720   \n",
       "2025-09-22 00:03:00   4.26534   4.26611  4.26534    4.26570   4.26770   \n",
       "2025-09-22 00:04:00   4.26606   4.26606  4.26560    4.26560   4.26792   \n",
       "\n",
       "                     ask_high  ask_low  ask_close   bid_avg   ask_avg  \\\n",
       "timestamp                                                               \n",
       "2025-09-22 00:00:00    4.2687  4.26725     4.2686  4.265448  4.267819   \n",
       "2025-09-22 00:01:00    4.2686  4.26715     4.2680  4.265488  4.267666   \n",
       "2025-09-22 00:02:00    4.2680  4.26720     4.2672  4.265453  4.267497   \n",
       "2025-09-22 00:03:00    4.2684  4.26720     4.2684  4.265753  4.267780   \n",
       "2025-09-22 00:04:00    4.2684  4.26784     4.2684  4.265877  4.268109   \n",
       "\n",
       "                     spread_avg  tick_count   mid_avg  log_mid_returns  \n",
       "timestamp                                                               \n",
       "2025-09-22 00:00:00    0.002371         111  4.266634        -0.000006  \n",
       "2025-09-22 00:01:00    0.002177          66  4.266577        -0.000013  \n",
       "2025-09-22 00:02:00    0.002044          33  4.266475        -0.000024  \n",
       "2025-09-22 00:03:00    0.002027          62  4.266767         0.000068  \n",
       "2025-09-22 00:04:00    0.002232          33  4.266993         0.000053  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/testset.csv', index_col=0, parse_dates=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b68eefb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['is_friday'] = (test.index.dayofweek == 4).astype(int)\n",
    "test['is_sunday'] = (test.index.dayofweek == 6).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "13fe56dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['spread_avg', 'tick_count', 'mid_avg', 'log_mid_returns', 'is_friday',\n",
       "       'is_sunday', 'logbid_open_returns', 'logbid_high_returns',\n",
       "       'logbid_low_returns', 'logbid_close_returns', 'logask_open_returns',\n",
       "       'logask_high_returns', 'logask_low_returns', 'logask_close_returns',\n",
       "       'logbid_avg_returns', 'logask_avg_returns'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wazne, aby najpierw przetransformowac raw prices features na log returns\n",
    "prices_to_log = ['bid_open', 'bid_high', 'bid_low', 'bid_close', 'ask_open', 'ask_high',\n",
    "       'ask_low', 'ask_close', 'bid_avg', 'ask_avg']\n",
    "for feature in prices_to_log:\n",
    "    test[f'log{feature}_returns'] = np.log(test[feature] / test[feature].shift(1))\n",
    "\n",
    "# i pozbyc sie raw prices\n",
    "test = test.drop(columns=['bid_open', 'bid_high', 'bid_low', 'bid_close', 'ask_open', 'ask_high',\n",
    "       'ask_low', 'ask_close', 'bid_avg', 'ask_avg'])\n",
    "\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3db49c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['spread_avg', 'tick_count', 'log_mid_returns', 'is_friday', 'is_sunday',\n",
       "       'logbid_open_returns', 'logbid_high_returns', 'logbid_low_returns',\n",
       "       'logbid_close_returns', 'logask_open_returns', 'logask_high_returns',\n",
       "       'logask_low_returns', 'logask_close_returns', 'logbid_avg_returns',\n",
       "       'logask_avg_returns'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we already have log_mid_returns, so let's drop mid_avg\n",
    "test = test.drop(columns=['mid_avg'])\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e555c146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n",
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\2619169018.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'{feat}_lag_{k}'] = test[feat].shift(k)\n"
     ]
    }
   ],
   "source": [
    "# W sumie lagujemy wszustkie features poza dniem - intersuje nas tylko czy dzis jest \n",
    "# piatek badz niedziela, a nie co bylo wczoraj badz przedwczoraj\n",
    "features_to_lag = ['spread_avg', 'tick_count', 'log_mid_returns',\n",
    "       'logbid_open_returns', 'logbid_high_returns', 'logbid_low_returns',\n",
    "       'logbid_close_returns', 'logask_open_returns', 'logask_high_returns',\n",
    "       'logask_low_returns', 'logask_close_returns', 'logbid_avg_returns',\n",
    "       'logask_avg_returns']\n",
    "\n",
    "# How many minutes back?\n",
    "lags = [1, 2, 3, 4,5,6,7,8,9,10]\n",
    "\n",
    "# Create lagged features - po shiftnieciu calego datasetu bedzie to dylemat ktory mam w zeszycie\n",
    "for feat in features_to_lag:\n",
    "    for k in lags:\n",
    "        test[f'{feat}_lag_{k}'] = test[feat].shift(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c352d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To zapewne stworzylo kilka NA\n",
    "# owszem. Usunmy je\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53dcdf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the threshold. It was important to use the median computed from train subset, to prevent data leakage in the test set (median contains some sort of infomration about future minutes)\n",
    "import json\n",
    "with open(\"threshold.json\", \"r\") as f:\n",
    "    thr = json.load(f)[\"thr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5db09a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp\n",
      "2025-09-22 00:11:00    0\n",
      "2025-09-22 00:12:00    0\n",
      "2025-09-22 00:13:00    0\n",
      "2025-09-22 00:14:00   -1\n",
      "2025-09-22 00:15:00   -1\n",
      "                      ..\n",
      "2025-10-05 23:55:00    0\n",
      "2025-10-05 23:56:00    0\n",
      "2025-10-05 23:57:00    0\n",
      "2025-10-05 23:58:00    0\n",
      "2025-10-05 23:59:00    0\n",
      "Name: target, Length: 13513, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Column with the log returns 3 minutes later\n",
    "#    So the value for the first minute, will be the log return for the 4th minute and so on...\n",
    "#    ATTENTION! Pracujemy na mid prices, a przeciez kupujemy za ASK, sprzedajemy po BID. Jest to slaba strona mojego projektu...\n",
    "test['log_mid_return_3+'] = test['log_mid_returns'].shift(-3)\n",
    "\n",
    "# 2. Define the threshold. let's take the absolute values of our log returns,\n",
    "#    and compute the median. The predicted log return 3 periods later being higher than half\n",
    "#    of the median will mean that we shouldnt stay flat\n",
    "thr = test['log_mid_returns'].abs().median() * 0.5\n",
    "\n",
    "\n",
    "# 3. Compute classification target\n",
    "# - jesli predicted log return is bigger than threshold (+ values), lets go long\n",
    "# - jesli predicted log return (bedacy zapwne minusowy) jest mniejszy niz liczba przeciwna \n",
    "#   do threshold, we go short\n",
    "# - Otherwise, stay flat\n",
    "# REMARK! I decided to penalize more the losses - that's why you can see -0.8 * thr\n",
    "y = np.where(test['log_mid_return_3+'] > thr, 1,\n",
    "    np.where(test['log_mid_return_3+'] < -0.8 * thr, -1, 0))\n",
    "\n",
    "y = pd.Series(y, index=test.index, name='target')\n",
    "\n",
    "\n",
    "# 4. - Prawie to mamy. Warto jeszcze jednak zauwazyc, ze ostatnie 5 minut przed zamknieciem gieldy (16:55-17:00) odpuscimy sobie tradowanie.\n",
    "# - Warto tez zauwazyc, ze pierwsze 10 min w niedziele nie beda posiadac lagow. Ale mozemy\n",
    "# to w sumie usunac prostym .droopna(), takze narazie sie tym nie przejmujemy\n",
    "from datetime import time\n",
    "idx = test.index\n",
    "\n",
    "friday_last5 = (\n",
    "    (idx.weekday == 4) &\n",
    "    (idx.time >= time(16, 55)) &\n",
    "    (idx.time <  time(17, 0))\n",
    ")\n",
    "y.loc[friday_last5] = 0\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ca607e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grzes\\AppData\\Local\\Temp\\ipykernel_27388\\1695130833.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test['target'] = y\n"
     ]
    }
   ],
   "source": [
    "test['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "33276565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spread_avg</th>\n",
       "      <th>tick_count</th>\n",
       "      <th>log_mid_returns</th>\n",
       "      <th>is_friday</th>\n",
       "      <th>is_sunday</th>\n",
       "      <th>logbid_open_returns</th>\n",
       "      <th>logbid_high_returns</th>\n",
       "      <th>logbid_low_returns</th>\n",
       "      <th>logbid_close_returns</th>\n",
       "      <th>logask_open_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>logask_avg_returns_lag_3</th>\n",
       "      <th>logask_avg_returns_lag_4</th>\n",
       "      <th>logask_avg_returns_lag_5</th>\n",
       "      <th>logask_avg_returns_lag_6</th>\n",
       "      <th>logask_avg_returns_lag_7</th>\n",
       "      <th>logask_avg_returns_lag_8</th>\n",
       "      <th>logask_avg_returns_lag_9</th>\n",
       "      <th>logask_avg_returns_lag_10</th>\n",
       "      <th>log_mid_return_3+</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-10-05 23:57:00</th>\n",
       "      <td>0.002510</td>\n",
       "      <td>14</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-05 23:58:00</th>\n",
       "      <td>0.002502</td>\n",
       "      <td>25</td>\n",
       "      <td>-4.231253e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-05 23:59:00</th>\n",
       "      <td>0.002510</td>\n",
       "      <td>22</td>\n",
       "      <td>4.231253e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     spread_avg  tick_count  log_mid_returns  is_friday  \\\n",
       "timestamp                                                                 \n",
       "2025-10-05 23:57:00    0.002510          14     2.220446e-16          0   \n",
       "2025-10-05 23:58:00    0.002502          25    -4.231253e-07          0   \n",
       "2025-10-05 23:59:00    0.002510          22     4.231253e-07          0   \n",
       "\n",
       "                     is_sunday  logbid_open_returns  logbid_high_returns  \\\n",
       "timestamp                                                                  \n",
       "2025-10-05 23:57:00          1             0.000000                  0.0   \n",
       "2025-10-05 23:58:00          1             0.000000                  0.0   \n",
       "2025-10-05 23:59:00          1            -0.000026                  0.0   \n",
       "\n",
       "                     logbid_low_returns  logbid_close_returns  \\\n",
       "timestamp                                                       \n",
       "2025-10-05 23:57:00                 0.0              0.000000   \n",
       "2025-10-05 23:58:00                 0.0              0.000026   \n",
       "2025-10-05 23:59:00                 0.0              0.000000   \n",
       "\n",
       "                     logask_open_returns  ...  logask_avg_returns_lag_3  \\\n",
       "timestamp                                 ...                             \n",
       "2025-10-05 23:57:00             0.000000  ...                 -0.000002   \n",
       "2025-10-05 23:58:00             0.000000  ...                  0.000005   \n",
       "2025-10-05 23:59:00             0.000068  ...                 -0.000001   \n",
       "\n",
       "                     logask_avg_returns_lag_4  logask_avg_returns_lag_5  \\\n",
       "timestamp                                                                 \n",
       "2025-10-05 23:57:00                  0.000002                  0.000013   \n",
       "2025-10-05 23:58:00                 -0.000002                  0.000002   \n",
       "2025-10-05 23:59:00                  0.000005                 -0.000002   \n",
       "\n",
       "                     logask_avg_returns_lag_6  logask_avg_returns_lag_7  \\\n",
       "timestamp                                                                 \n",
       "2025-10-05 23:57:00                  0.000027                 -0.000028   \n",
       "2025-10-05 23:58:00                  0.000013                  0.000027   \n",
       "2025-10-05 23:59:00                  0.000002                  0.000013   \n",
       "\n",
       "                     logask_avg_returns_lag_8  logask_avg_returns_lag_9  \\\n",
       "timestamp                                                                 \n",
       "2025-10-05 23:57:00                 -0.000018                  0.000011   \n",
       "2025-10-05 23:58:00                 -0.000028                 -0.000018   \n",
       "2025-10-05 23:59:00                  0.000027                 -0.000028   \n",
       "\n",
       "                     logask_avg_returns_lag_10  log_mid_return_3+  target  \n",
       "timestamp                                                                  \n",
       "2025-10-05 23:57:00                   0.000004                NaN       0  \n",
       "2025-10-05 23:58:00                   0.000011                NaN       0  \n",
       "2025-10-05 23:59:00                  -0.000018                NaN       0  \n",
       "\n",
       "[3 rows x 147 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e49a1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8ce1fbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "64034ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns= ['log_mid_return_3+'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0ab5ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"algo_test_processed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
